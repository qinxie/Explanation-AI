{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qinxie/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/qinxie/2018/2018 second semester/2018LRP/LRP explain time series dataset/LRP explain time series dataset/Prepare v1/models')\n",
    "from models_2_2 import MNIST_DNN\n",
    "from utils import pixel_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "images = mnist.train.images\n",
    "labels = mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'tf_logs/STD_V5'\n",
    "ckptdir = logdir + '/model'\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>__Building Graph__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, a regular DNN classifier is initialized and necessary nodes for model training is added onto the graph. In this particular tutorial, I used a fully connected neural network with ReLU activations and without bias in order to satisfy the $f(tx) = tf(x)$ property mentioned in the introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-3a5bc5d411c4>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('Classifier'):\n",
    "    \n",
    "    #initial neural network\n",
    "    DNN = MNIST_DNN('DNN')\n",
    "    \n",
    "    #setup training process\n",
    "    X = tf.placeholder(tf.float32, [None, 784], name='X')\n",
    "    Y = tf.placeholder(tf.float32, [None, 10], name='Y')\n",
    "\n",
    "    activations,logits = DNN(X)\n",
    "    \n",
    "    tf.add_to_collection('STD', X)\n",
    "#     tf.add_to_collection('STD', logits)\n",
    "    for activation in activations:\n",
    "        tf.add_to_collection('STD', activation)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost, var_list=DNN.vars)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "cost_summary = tf.summary.scalar('Cost', cost)\n",
    "accracy_summary = tf.summary.scalar('Accuracy', accuracy)\n",
    "summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>__Training Network__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the step where the DNN is trained to classify the 10 digits of the MNIST images. Summaries are written into the logdir and you can visualize the statistics using tensorboard by typing this command: tensorboard --lodir=/tf_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('epoch:', '0001', 'cost = ', '0.222180229', 'accuracy = ', '0.932200004')\n",
      "('epoch:', '0002', 'cost = ', '0.096898515', 'accuracy = ', '0.971072736')\n",
      "('epoch:', '0003', 'cost = ', '0.065677645', 'accuracy = ', '0.980054556')\n",
      "('epoch:', '0004', 'cost = ', '0.051179192', 'accuracy = ', '0.983945466')\n",
      "('epoch:', '0005', 'cost = ', '0.040895103', 'accuracy = ', '0.987672735')\n",
      "('epoch:', '0006', 'cost = ', '0.034696673', 'accuracy = ', '0.989454554')\n",
      "('epoch:', '0007', 'cost = ', '0.030927487', 'accuracy = ', '0.990872735')\n",
      "('epoch:', '0008', 'cost = ', '0.028013923', 'accuracy = ', '0.991581825')\n",
      "('epoch:', '0009', 'cost = ', '0.024057186', 'accuracy = ', '0.992872734')\n",
      "('epoch:', '0010', 'cost = ', '0.022129803', 'accuracy = ', '0.993490915')\n",
      "('epoch:', '0011', 'cost = ', '0.019094508', 'accuracy = ', '0.994109097')\n",
      "('epoch:', '0012', 'cost = ', '0.017918524', 'accuracy = ', '0.994600005')\n",
      "('epoch:', '0013', 'cost = ', '0.016289875', 'accuracy = ', '0.995418186')\n",
      "('epoch:', '0014', 'cost = ', '0.017908563', 'accuracy = ', '0.994563641')\n",
      "('epoch:', '0015', 'cost = ', '0.017066962', 'accuracy = ', '0.995218186')\n",
      "('accuracy:', 0.981)\n"
     ]
    }
   ],
   "source": [
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "#hyper parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    avg_acc = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c, a, summary_str = sess.run([optimizer, cost, accuracy, summary], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        avg_cost += c / total_batch\n",
    "        avg_acc += a / total_batch\n",
    "        \n",
    "        file_writer.add_summary(summary_str, epoch * total_batch + i)\n",
    "        \n",
    "    print('epoch:', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost), 'accuracy = ', '{:.9f}'.format(avg_acc))\n",
    "    \n",
    "    saver.save(sess, ckptdir)\n",
    "    \n",
    "print('accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>__Restoring Subgraph__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_saver = tf.train.import_meta_graph(ckptdir+'.meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tf_logs/STD_V5/model\n"
     ]
    }
   ],
   "source": [
    "new_saver.restore(sess, tf.train.latest_checkpoint(logdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='DNN')\n",
    "activations = tf.get_collection('STD')\n",
    "X = activations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Classifier/X:0\", shape=(?, 784), dtype=float32)\n",
      "\n",
      "<tf.Variable 'DNN/dense/kernel:0' shape=(784, 512) dtype=float32_ref>\n",
      "<tf.Variable 'DNN/dense_1/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'DNN/dense_2/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'DNN/dense_3/kernel:0' shape=(512, 512) dtype=float32_ref>\n",
      "<tf.Variable 'DNN/dense_4/kernel:0' shape=(512, 10) dtype=float32_ref>\n",
      "\n",
      "('activations', <tf.Tensor 'Classifier/X:0' shape=(?, 784) dtype=float32>)\n",
      "('activations', <tf.Tensor 'Classifier/DNN/dense/Relu:0' shape=(?, 512) dtype=float32>)\n",
      "('activations', <tf.Tensor 'Classifier/DNN/dense_1/Relu:0' shape=(?, 512) dtype=float32>)\n",
      "('activations', <tf.Tensor 'Classifier/DNN/dense_2/Relu:0' shape=(?, 512) dtype=float32>)\n",
      "('activations', <tf.Tensor 'Classifier/DNN/dense_3/Relu:0' shape=(?, 512) dtype=float32>)\n",
      "('activations', <tf.Tensor 'Classifier/DNN/dense_4/MatMul:0' shape=(?, 10) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print\n",
    "for i in range(len(weights)):\n",
    "    print(weights[i])\n",
    "print\n",
    "for i in range(len(activations)):\n",
    "    print('activations',activations[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass_rel(top_rel, inputs, weights, outputs, epsilon=1e-4):\n",
    "    return np.sum((inputs.T.dot(top_rel) * weights) / (outputs + epsilon),\n",
    "                          axis=1,\n",
    "                          keepdims=True).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_taylor_rel(inputs, weights, top_rel, lowest=-1.5, highest=2.5):\n",
    "    w_p = np.maximum(np.zeros_like(weights), weights)\n",
    "    w_n = np.minimum(np.zeros_like(weights), weights)\n",
    "    \n",
    "    L = np.ones_like(inputs) * lowest\n",
    "    H = np.ones_like(inputs) * highest\n",
    "    \n",
    "    z_o = inputs.dot(weights)\n",
    "    z_p = L.dot(w_p)\n",
    "    z_n = H.dot(w_n)\n",
    "    \n",
    "    z = z_o - z_p - z_n + 1e-10\n",
    "    s = top_rel / z\n",
    "    \n",
    "    c_o = s.dot(weights.T)\n",
    "    c_p = s.dot(w_p.T)\n",
    "    c_n = s.dot(w_n.T)\n",
    "    \n",
    "    return inputs * c_o - L * c_p + H * c_n    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_a_p(x, y,z,epsilon=1e-4):\n",
    "    n_dx = x.shape[1]\n",
    "    n_dy = y.shape[1]  #number of columns\n",
    "    e_x = np.sum(x, axis=0) # axis=0, means add every row entry, eg. if it is a row array(horizontal vector), then the result is the same as the row array. So, here, np.shape(e_x)=np.shape(x)\n",
    "    e_x = np.where(e_x > 0, e_x, 0)\n",
    "    e_y = np.sum(y, axis=0)\n",
    "    e_y2 = np.sum(y**2, axis=0)\n",
    "    for i in range(n_dy):\n",
    "        if i==0:\n",
    "#             e_xy = np.sum(x * np.repeat(y[:,i:(i+1)], n_dx, axis=1), axis=0)\n",
    "            e_xy = np.sum(x * y[:,[i]], axis=0)\n",
    "            e_xy = np.where(e_xy>0, e_xy, 0)\n",
    "            a = (e_xy - e_x * e_y[i]) / (z[:,i].T * e_xy - z[:,i].T * e_x * e_y[i] + epsilon)\n",
    "        else:\n",
    "#             e_xy = np.sum(x * np.repeat(y[:,i:(i+1)], n_dx, axis=1), axis=0)\n",
    "            e_xy = np.sum(x * y[:,[i]], axis=0)\n",
    "            e_xy = np.where(e_xy>0, e_xy, 0)\n",
    "            a_n = (e_xy - e_x * e_y[i]) / (z[:,i].T * e_xy  - z[:,i].T * e_x * e_y[i] + epsilon)\n",
    "            a = np.vstack((a, a_n))\n",
    "    a = a.transpose()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_a_n(x, y,z, epsilon=1e-4):\n",
    "    n_dx = x.shape[1]\n",
    "    n_dy = y.shape[1]\n",
    "    e_x = np.sum(x, axis=0)\n",
    "    e_x = np.where(e_x < 0, e_x, 0)\n",
    "    e_y = np.sum(y, axis=0)\n",
    "    e_y2 = np.sum(y**2, axis=0)\n",
    "    for i in range(n_dy):\n",
    "        if i==0:\n",
    "            e_xy = np.sum(x * np.repeat(y[:,i:(i+1)], n_dx, axis=1), axis=0)  # repeat each colume n_dx times\n",
    "            e_xy = np.where(e_xy<0, e_xy, 0)\n",
    "            a = (e_xy - e_x * e_y[i]) / (z[:,i].T * e_xy - z[:,i].T * e_x * e_y[i] + epsilon)\n",
    "        else:\n",
    "            e_xy = np.sum(x * np.repeat(y[:,i:(i+1)], n_dx, axis=1), axis=0)\n",
    "            e_xy = np.where(e_xy<0, e_xy, 0)\n",
    "            a_n = (e_xy - e_x * e_y[i]) / (z[:,i].T * e_xy  - z[:,i].T * e_x * e_y[i] + epsilon)\n",
    "            a = np.vstack((a, a_n))\n",
    "    a = a.transpose()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ = sess.run(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_ = sess.run(activations, feed_dict={X: images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dense5_p = cal_a_p(activations_[4], activations_[5], weights_[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dense4_p = cal_a_p(activations_[3], activations_[4], weights_[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dense3_p = cal_a_p(activations_[2], activations_[3], weights_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dense2_p = cal_a_p(activations_[1], activations_[2], weights_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dense1_p = cal_a_p(activations_[0], activations_[1], weights_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_imgs = []\n",
    "for i in range(10):\n",
    "#     sample_imgs.append(images[np.argmax(labels, axis=1) == i][3])\n",
    "    sample_imgs.append(images[np.argmax(labels, axis=1) == i][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_samples = sess.run(activations, feed_dict={X:sample_imgs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(activations_samples[4]))\n",
    "# print(activations_samples[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PatternAttribute p\n",
    "temp1_p = backprop_taylor_rel(activations_samples[4], weights_[4]*a_dense5_p, activations_samples[5])\n",
    "temp1_p = backprop_taylor_rel(activations_samples[3], weights_[3]*a_dense4_p, temp1_p)\n",
    "temp1_p = backprop_taylor_rel(activations_samples[2], weights_[2]*a_dense3_p, temp1_p)\n",
    "temp1_p = backprop_taylor_rel(activations_samples[1], weights_[1]*a_dense2_p, temp1_p)\n",
    "temp1_p = backprop_taylor_rel(activations_samples[0], weights_[0]*a_dense1_p, temp1_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(temp1_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.reshape(temp1_n[2], [28,28]), cmap='gray')\n",
    "# vmin, vmax = pixel_range(temp1_p[1])\n",
    "plt.imshow(np.reshape(temp1_p[2], [28,28]),cmap='bwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i in range(5):\n",
    "    plt.subplot(5, 2, 2 * i + 1)\n",
    "#     plt.imshow(np.reshape(sample_imgs[2*i], [28,28]), cmap='gray')\n",
    "    plt.imshow(np.reshape(temp1_p[2 * i], [28, 28]), cmap='bwr')\n",
    "#     plt.imshow(np.reshape(temp1_p[2 * i], [28, 28]), cmap='hot_r')\n",
    "#     plt.imshow(np.reshape(temp1_p[2], [28,28]), cmap='gray')\n",
    "    plt.title('Digit: {}'.format(2 * i))\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.subplot(5, 2, 2 * i + 2)\n",
    "#     plt.imshow(np.reshape(sample_imgs[2*i +1], [28,28]), cmap='gray')\n",
    "#     plt.imshow(np.reshape(temp1_p[2 * i + 1], [28, 28]), cmap='bwr')\n",
    "#     plt.imshow(np.reshape(temp1_p[2 * i + 1], [28, 28]), cmap='hot_r')\n",
    "    plt.imshow(np.reshape(temp1_p[2 * i+1], [28,28]),cmap='bwr')\n",
    "    plt.title('Digit: {}'.format(2 * i + 1))\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i in range(5):\n",
    "    plt.subplot(5, 2, 2 * i + 1)\n",
    "    plt.imshow(np.reshape(sample_imgs[2 * i], [28, 28]), cmap='hot_r')\n",
    "    plt.title('Digit: {}'.format(2 * i))\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.subplot(5, 2, 2 * i + 2)\n",
    "    plt.imshow(np.reshape(sample_imgs[2 * i + 1], [28, 28]), cmap='hot_r')\n",
    "    plt.title('Digit: {}'.format(2 * i + 1))\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>__Calculating Relevance Scores $R(x_i)$__</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = mnist.train.images\n",
    "# labels = mnist.train.labels\n",
    "\n",
    "# sample_imgs = []\n",
    "# for i in range(10):\n",
    "#     sample_imgs.append(images[np.argmax(labels, axis=1) == i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (np.shape(images))\n",
    "# print(np.shape(labels))\n",
    "# print(labels[44])\n",
    "# print ('np.shape(images[np.argmax(labels, axis=1) == 0]) :',np.shape(images[np.argmax(labels, axis=1) == 0]))\n",
    "# print (np.shape(images[np.argmax(labels, axis=1) == 0][3]))\n",
    "# print('np.shape(sample_imgs): ',np.shape(sample_imgs))\n",
    "# print(np.shape(sample_imgs)[1])\n",
    "# print(np.shape(sample_imgs[1][None,:]))\n",
    "# print(np.argmax(labels, axis=1) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,15))\n",
    "# for i in range(5):\n",
    "#     plt.subplot(5,2,2*i+1)\n",
    "#     plt.imshow(np.reshape(sample_imgs[2*i], [28,28]), cmap='gray')\n",
    "    \n",
    "#     vmin, vmax = pixel_range(hmaps[2 * i])\n",
    "#     plt.imshow(np.reshape(hmaps[2*i], [28,28]), vmin=vmin, vmax=vmax, cmap='bwr', alpha=0.5)\n",
    "#     plt.title('digit:{}'.format(2*i))\n",
    "#     plt.colorbar()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
